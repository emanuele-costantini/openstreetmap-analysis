{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "La previsione dell'indice giornaliero futuro di rischio incidenti si baserà su tre tipi di features:\n",
    "- <font color=\"dodgerblue\">**features spaziali**</font>: features statiche che fanno riferimento alla geografia urbana della zona specifica e permettono di discriminare la pericolosità di un punto in città rispetto ad un altro. Variano abbastanza lentamente nel tempo da essere considerate statiche.\n",
    "- <font color=\"dodgerblue\">**features temporali**</font>: features dinamiche che cambiano in base al giorno ma sono abbastanza uniformi a livello spaziale; permettono di discrimare la pericolosità di un giorno rispetto ad un altro. Es. meteo, giorno della settimana...\n",
    "- <font color=\"dodgerblue\">**features miste**</font>: features che variano in base al giorno ma possono essere piuttosto eterogenee anche a livello geografico. Es. traffico o eventi in specifiche zone della città, storico di incidenti nella zona.\n",
    "\n",
    "La combinazione di questi 3 tipi di features permette di avere variabili variegate in input a un modello di Machine Learning e riuscire ad effettuare una previsione più accurata sia nel tempo che nello spazio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"USE_PYGEOS\"] = \"0\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import folium\n",
    "import geojson\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from pointpats import centrography\n",
    "from pyproj import Transformer\n",
    "from shapely import wkt, buffer\n",
    "from shapely.geometry import Polygon, Point\n",
    "from shapely.prepared import prep\n",
    "from sklearn.cluster import DBSCAN\n",
    "from google.cloud import storage as gcs\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../serviceaccount-piattaformapa-test.json\"\n",
    "\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"city\": \"Milan\",\n",
    "    \"grid\": \n",
    "        {\n",
    "            \"hexagon_height\": 1000\n",
    "        },\n",
    "    \"clustering\":\n",
    "        {\n",
    "            \"dbscan\": \n",
    "                {\n",
    "                    \"min_samples\": 4,\n",
    "                    \"eps\": 30,\n",
    "                },\n",
    "            \"shared_grid\": \"cluster_hull\"   # choose between \"cluster_hull\" or \"enc_circle\"\n",
    "        },\n",
    "    \"centrality\":\n",
    "        {\n",
    "            \"percentile\": 0.9,\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_roads = \"bucket-cityroads-data-test\"\n",
    "bucket_boundaries = \"bucket-city-boundaries-data-test\"\n",
    "\n",
    "nil_file = \"nil.geojson\"\n",
    "municipi_file = \"municipi.geojson\"\n",
    "\n",
    "city = \"Milan\"\n",
    "\n",
    "client = gcs.Client()\n",
    "\n",
    "# city boundaries\n",
    "bucket_boundaries = client.get_bucket(bucket_boundaries)\n",
    "\n",
    "nil = bucket_boundaries.blob(nil_file)\n",
    "municipi = bucket_boundaries.blob(municipi_file)\n",
    "\n",
    "with nil.open() as f:\n",
    "    nil_dict = geojson.load(f)\n",
    "nil_df = gpd.read_file(nil.open())\n",
    "nil_features = nil_dict[\"features\"]\n",
    "\n",
    "with municipi.open() as f:\n",
    "    municipi_dict = geojson.load(f)\n",
    "municipi_df = gpd.read_file(municipi.open())\n",
    "municipi_features = municipi_dict[\"features\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisione della città in zone\n",
    "\n",
    "Come anticipato, la predizione dell'indice di rischio sarà divisa per \"zone\", in modo da discriminare i diversi punti della città, potenzialmente molto diversi a livello di rischio incidenti.\n",
    "\n",
    "La divisione per zone non può avvenire per municipi o quartieri, trattandosi di divisioni territoriali irregolari e di diverse dimensioni.<br>\n",
    "Per ovviare a tale problema, si divide la città in **griglie esagonali** (ref link: [Why hexagons?](https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/h-whyhexagons.htm)). La dimesione delle griglie è fissa ed è un iperparametro del problema ma va scelta secondo i seguenti ragionamenti:\n",
    "- griglie troppo grandi: dimensione ridotta del dataset, predizioni troppo grezze e incapacità di dividere correttamente le diverse zone della città.\n",
    "- griglie troppo piccole: incapacità di estrarre pattern geografici e temporali significativi dovuta a un'osservazione troppo puntuale (rischio di ottenere features uguali per tutte le griglie).\n",
    "\n",
    "La dimensione ottima è quella che consente di avere una griglia abbastanza fine ma che riesca a dividere intelligentemente zone diverse.\n",
    "\n",
    "Ad ogni griglia viene poi associato il/i corrispondete/i nil e municipi con la corrispondete percentuale di copertura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_gdf = ox.geocode_to_gdf({\"city\": city})\n",
    "city_geom = city_gdf.geometry[0]\n",
    "\n",
    "# boundaries of the city (coordinates)\n",
    "minx, miny, maxx, maxy = city_geom.bounds\n",
    "\n",
    "trans_direct = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32632\", always_xy=True)\n",
    "trans_inverse = Transformer.from_crs(\"EPSG:32632\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# Temporarly transform coordinates so that we can work directly with distances\n",
    "minx, miny = (int(res) for res in trans_direct.transform(minx, miny))\n",
    "maxx, maxy = (int(res) for res in trans_direct.transform(maxx, maxy))\n",
    "\n",
    "# Define height and radius of each hexagon\n",
    "h = hyperparams[\"grid\"][\"hexagon_height\"]\n",
    "r = int(h / math.sqrt(3))\n",
    "\n",
    "\n",
    "# Initialize geo dictionary for grids (it can be useful to save as .geojson)\n",
    "hex_geo_dict = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"name\": \"hex_grids_{}\".format(city),\n",
    "    \"features\": []\n",
    "}\n",
    "\n",
    "\n",
    "def hex_grid(h, r):\n",
    "\n",
    "    # Assign to each grid an id trough\n",
    "    cont = 0\n",
    "\n",
    "    # Iterate along x and y axis\n",
    "    for x in range(minx, maxx, h):\n",
    "        for y in range(miny, maxy, int(h * h / r / 2)):\n",
    "            # hexagon geometry\n",
    "            hexagon = Polygon([\n",
    "                        [*trans_inverse.transform(x, y + r)],\n",
    "                        [*trans_inverse.transform(x + h / 2, y + r / 2)],\n",
    "                        [*trans_inverse.transform(x + h / 2, y - r / 2)],\n",
    "                        [*trans_inverse.transform(x, y - r)],\n",
    "                        [*trans_inverse.transform(x - h / 2, y - r / 2)],\n",
    "                        [*trans_inverse.transform(x - h / 2, y + r / 2)],\n",
    "                        [*trans_inverse.transform(x, y + r)],\n",
    "                    ])\n",
    "\n",
    "            # List of intersected nils and municipi for each grid\n",
    "            nil_list = []\n",
    "            municipi_list = []\n",
    "\n",
    "            # List of weights for each intersected nils and municipi for each grid\n",
    "            nil_perc = []\n",
    "            municipi_perc = []\n",
    "\n",
    "            for nil in nil_features:\n",
    "                prepared_geom = prep(Polygon(nil[\"geometry\"][\"coordinates\"][0]))\n",
    "                # Only save if the grid intersects any nil\n",
    "                if prepared_geom.intersects(hexagon):\n",
    "                    # Compute percentage of intersection area\n",
    "                    perc_area = round(\n",
    "                        hexagon.intersection(Polygon(nil[\"geometry\"][\"coordinates\"][0])).area/hexagon.area,\n",
    "                        3,\n",
    "                    )\n",
    "                    # Save nil infos\n",
    "                    nil_list.append(nil[\"properties\"][\"NIL\"])\n",
    "                    nil_perc.append(perc_area)\n",
    "\n",
    "            # Same for municipi\n",
    "            for mun in municipi_features:\n",
    "                prepared_geom = prep(Polygon(mun[\"geometry\"][\"coordinates\"][0]))\n",
    "                if prepared_geom.intersects(hexagon):\n",
    "                    perc_area = round(\n",
    "                        hexagon.intersection(Polygon(mun[\"geometry\"][\"coordinates\"][0])).area/hexagon.area,\n",
    "                        3,\n",
    "                    )\n",
    "                    municipi_list.append(mun[\"id\"])\n",
    "                    municipi_perc.append(perc_area)\n",
    "\n",
    "            # Grid is saved only if its intersection is non empty\n",
    "            if (len(municipi_list) > 0) or (len(nil_list) > 0):\n",
    "                final_dict = {\n",
    "                    \"type\": \"Feature\",\n",
    "                    \"id_grid\": cont,\n",
    "                    \"nil_list\": nil_list,\n",
    "                    \"nil_weights\": nil_perc,\n",
    "                    \"municipi_list\": municipi_list,\n",
    "                    \"municipi_weights\": municipi_perc,\n",
    "                    \"geometry\": hexagon,\n",
    "                }\n",
    "\n",
    "                hex_geo_dict[\"features\"].append(final_dict)\n",
    "                cont += 1\n",
    "            \n",
    "            # offset to be added to avoid overlapping of hexagons\n",
    "            i = math.floor((maxy - y) / r)\n",
    "            offset = -h / 2 if i % 2 == 0 else h / 2\n",
    "\n",
    "            x += offset\n",
    "\n",
    "    print(\"Drawn {} hexagon grids with height {} meters\".format(cont, h))\n",
    "\n",
    "hex_grid(h, r)\n",
    "\n",
    "hex_df = gpd.GeoDataFrame(hex_geo_dict[\"features\"], geometry=\"geometry\", crs=4326).drop(columns=\"type\")\n",
    "hex_df.sample(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Feature Engineering (dati da OpenStreetMap)\n",
    "\n",
    "La prima fase di feature engineering consiste nell'estrazione, processing, aggregazione di dati spaziali in ambito urbano e conseguente associazione spaziale con ogni griglia.\n",
    "\n",
    "Vengono estratte informazioni che sono notoriamente più rilevanti e correlate con il rischio di incidenti:\n",
    "- <font color=\"dodgerblue\">**semafori**</font>\n",
    "- <font color=\"dodgerblue\">**precedenze e stop**</font>\n",
    "- <font color=\"dodgerblue\">**rotatorie**</font>\n",
    "- <font color=\"dodgerblue\">**rotaie tram**</font>\n",
    "- <font color=\"dodgerblue\">**manto stradale**</font>\n",
    "\n",
    "Tali informazioni vengono poi processate per creare delle features rilevanti per ogni griglia.\n",
    "\n",
    "Viene inoltre estratto l'intero <font color=\"dodgerblue\">**reticolo stradale**</font> della città di interesse.<br>\n",
    "Quest'ultima estrazione permette di rappresentare le strade di una città come un **_grafo_** (gli archi sono i segmenti di strada e i nodi le intersezioni tra di esse), ed estrarre dei pattern interessanti dal punto di vista della viabilità:\n",
    "- <font color=\"dodgerblue\">**strade più importanti**</font>: l'importanza di una strada può essere associate ad alcune metriche di centralità di nodi in un grafo (dettagli in seguito).\n",
    "\n",
    "L'informazione sull'importanza delle strade viene poi processata per creare delle features per ogni griglia."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graph analysis\n",
    "\n",
    "Le strade di una città possono essere rappresentate come un grafo, sul quale possono essere applicati degli algoritmi per capire quali archi (strade) sono le più importanti e critiche all'interno del dominio della città, secondo vari metriche:\n",
    "- **Betweeneess centrality**: misura quante volte un nodo risiede nel percorso più veloce tra due nodi. I nodi, e le strade associate, che hanno un alto punteggio, hanno un'influenza più alta negli spostamenti all'interno del grafo.\n",
    "- **Closeness centrality**: misura la distanza media di ogni nodo dagli altri nodi. Un punteggio alto identifica quindi i nodi (e strade) più \"centrali\" nella città.\n",
    "- **Node degree**: il numero di segmenti stradali che entrano ed escono da ogni nodo. Le strade identificate da due nodi con alto punteggio, sono quelle nelle quali affluiscono più strade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_roads = \"bucket-cityroads-data-test\"\n",
    "\n",
    "csv_roads_iter = client.list_blobs(bucket_roads, prefix=\"Milan\")\n",
    "\n",
    "\n",
    "# city items\n",
    "df_dict = {}\n",
    "\n",
    "for blob in csv_roads_iter:\n",
    "    df_path = \"gs://{}/{}\".format(bucket_roads, blob.name)\n",
    "    df_name = re.split(\"\\/|\\.\", blob.name)[1]\n",
    "    df = pd.read_csv(df_path)\n",
    "    df[\"geometry\"] = df[\"geometry\"].apply(wkt.loads)\n",
    "    if df_name != \"roads_graph_data\":\n",
    "        df[\"type\"] = df_name\n",
    "    df_dict[df_name] = gpd.GeoDataFrame(df, crs=\"epsg:4326\", geometry=\"geometry\")\n",
    "\n",
    "percentile = hyperparams[\"centrality\"][\"percentile\"]\n",
    "perc_dict = {}\n",
    "\n",
    "col_perc_exclusion = [\n",
    "    \"name\",\n",
    "    \"u\",\n",
    "    \"v\",\n",
    "    \"oneway\",\n",
    "    \"lanes\",\n",
    "    \"highway\",\n",
    "    \"geometry\",\n",
    "    \"junction\",\n",
    "    \"point_geometry_u\",\n",
    "    \"point_geometry_v\",\n",
    "]\n",
    "\n",
    "col_percentile_list = [\n",
    "    col for col in df_dict[\"roads_graph_data\"] if col not in col_perc_exclusion\n",
    "]\n",
    "\n",
    "for col in col_percentile_list:\n",
    "    perc_dict[col] = df_dict[\"roads_graph_data\"][col].quantile(percentile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_centrality(df, col, color, m, only_main):\n",
    "    if only_main:\n",
    "        df_filt = df[\n",
    "            (df[\"avg_sub_\" + col] > perc_dict[\"avg_sub_\" + col])\n",
    "        ]\n",
    "        df_filt\\\n",
    "            .explore(name=col + \" main edges\", m=m, color=color, style_kwds = {\"weight\": 2})\n",
    "    else:\n",
    "        df.explore(\n",
    "            name=col + \" edges\",\n",
    "            m=m,\n",
    "            column=\"avg_sub_\" + col,\n",
    "            cmap=\"seismic\",\n",
    "            style_kwds = {\"weight\": 2}\n",
    "        )\n",
    "\n",
    "def plot_items(m):\n",
    "    cs = iter([\"red\", \"blue\", \"orange\", \"green\", \"eggshell\", \"black\"])\n",
    "    for key, df in df_dict.items():\n",
    "        if key in [\"roads_graph_data\", \"parcometri\", \"colonnine\"]:\n",
    "            continue\n",
    "        df.explore(\n",
    "            name=key,\n",
    "            column=\"surface_mapped\" if key == \"manto_stradale\" else None,\n",
    "            m=m,\n",
    "            color=None if key == \"manto_stradale\" else next(cs),\n",
    "            cmap=[\"red\", \"blue\"] if key == \"manto_stradale\" else None,\n",
    "        )\n",
    "\n",
    "def plot_grid_nil_municipi(nil_and_municipi):\n",
    "    city_map = city_gdf.explore(\n",
    "    name=\"Milan urban perimeter\",\n",
    "    # tiles=\"OpenStreetMap Mapnik\",\n",
    "    style_kwds = {\n",
    "        \"fill\": False,\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 3\n",
    "    }\n",
    "    )\n",
    "    hex_df.explore(\n",
    "    name=\"hex grid\",\n",
    "    m=city_map,\n",
    "    style_kwds = {\n",
    "        \"fill\": False,\n",
    "        \"color\": \"red\",\n",
    "        \"fillColor\": \"white\",\n",
    "        \"fillOpacity\": 0.1,\n",
    "        \"weight\": 2,\n",
    "    },\n",
    ")\n",
    "    if nil_and_municipi:\n",
    "        gpd.GeoDataFrame.from_features(nil_dict[\"features\"]).explore(\n",
    "            name=\"nil\",\n",
    "            m=city_map,\n",
    "            style_kwds = {\n",
    "                \"fill\": False,\n",
    "                \"color\": \"blue\",\n",
    "                \"fillColor\": \"white\",\n",
    "                \"fillOpacity\": 0.1,\n",
    "                \"weight\": 1.5,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        gpd.GeoDataFrame.from_features(municipi_dict[\"features\"]).explore(\n",
    "            name=\"municipi\",\n",
    "            m=city_map,\n",
    "            style_kwds = {\n",
    "                \"fill\": False,\n",
    "                \"color\": \"green\",\n",
    "                \"fillColor\": \"white\",\n",
    "                \"fillOpacity\": 0.1,\n",
    "                \"weight\": 1.5,\n",
    "            },\n",
    "        )\n",
    "    return city_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_map_items = plot_grid_nil_municipi(nil_and_municipi=True)\n",
    "\n",
    "plot_items(city_map_items)\n",
    "\n",
    "folium.LayerControl(collapsed=False).add_to(city_map_items)\n",
    "\n",
    "city_map_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_metrics = {\n",
    "    \"closeness\": \"red\",\n",
    "    \"betweenness\": \"blue\",\n",
    "    # \"pagerank\": \"orange\",\n",
    "    # \"degree\": \"green\",\n",
    "    \"adjacent_roads\": \"dodgerblue\",\n",
    "}\n",
    "only_main = True\n",
    "\n",
    "\n",
    "city_map_centrality = plot_grid_nil_municipi(nil_and_municipi=True)\n",
    "\n",
    "for cen, color in centrality_metrics.items():\n",
    "    plot_centrality(\n",
    "        df=df_dict[\"roads_graph_data\"],\n",
    "        col=cen,\n",
    "        color=color,\n",
    "        m=city_map_centrality,\n",
    "        only_main=only_main,\n",
    "    )\n",
    "\n",
    "folium.LayerControl(collapsed=False).add_to(city_map_centrality)\n",
    "\n",
    "city_map_centrality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Identificazione punti critici tramite clustering\n",
    "\n",
    "Un altro modo per identificare i punti più caldi della viabilità urbana è identificare gli spots nei quali si concentra un alto numero di semafori. Questi punti potrebbero essere soggetti a un maggior numero di incidenti proprio per la presenza concentrata di elementi di controllo del traffico.\n",
    "\n",
    "Per identificare questi punti critici, si può utilizzare un algoritmo di clustering come DBSCAN, che tramite il tuning alcuni parametri, riesce automaticamente a separare punti fortemente clusterizzati da quelli più isolati.\n",
    "\n",
    "Il convex hull di ogni cluster viene poi intersecato geograficamente con le griglie.<br>\n",
    "Alcuni cluster possono cadere tra due o più griglie: in questo caso il cluster viene assegnato ad ogni griglia, ma viene anche riportato il numero effettivo di elementi nel cluster appartenente alla griglia.\n",
    "\n",
    "Le features estratte per ogni griglia sono quindi le seguenti:\n",
    "- <font color=\"dodgerblue\">**numero di cluster**</font>\n",
    "- <font color=\"dodgerblue\">**numero di elementi del cluster più grande**</font>\n",
    "- <font color=\"dodgerblue\">**numero medio di elementi dei cluster**</font>\n",
    "- <font color=\"dodgerblue\">**percentuale di elementi in cluster condivisi che appartengono alla griglia**</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Numero di elementi e metri totali di categorie di strada\n",
    "\n",
    "Tramite le informazioni citate sopra, possono essere create delle features per ogni griglia:\n",
    "- <font color=\"dodgerblue\">**Numero di semafori**</font>\n",
    "- <font color=\"dodgerblue\">**Numero di stop**</font>\n",
    "- <font color=\"dodgerblue\">**Numero di precedenze**</font>\n",
    "- <font color=\"dodgerblue\">**Metri totali di rotatorie**</font>\n",
    "- <font color=\"dodgerblue\">**Metri totali di rotaie tram**</font>\n",
    "- <font color=\"dodgerblue\">**Percentuale di strade asfaltate**</font>\n",
    "- <font color=\"dodgerblue\">**lunghezza totale strade**</font>\n",
    "- <font color=\"dodgerblue\">**lunghezza totale per tipologia di strada**</font>: residenziale, primaria, secondaria, terziaria.\n",
    "\n",
    "L'analisi sul grafo permette invece di creare altri tipi di features:\n",
    "- <font color=\"dodgerblue\">**Punteggio medio di centralità delle strade**</font>: Per ognuno dei punteggi citati sopra.\n",
    "- <font color=\"dodgerblue\">**metri di strade con punteggio di centralità sopra il 90esimo percentile**</font>: Per ognuno dei punteggi citati sopra.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smallest_enclosing_circle(df):\n",
    "    center = Point(centrography.mean_center(\n",
    "        df[[\"x\", \"y\"]].values,\n",
    "    ))\n",
    "\n",
    "    max_dist = 0\n",
    "    for p in df[\"geometry\"]:\n",
    "        dist = p.distance(center)\n",
    "        if dist > max_dist:\n",
    "            max_dist = dist\n",
    "    return buffer(center, max_dist)\n",
    "\n",
    "def cluster_items(df, item):\n",
    "    clusterer = DBSCAN(\n",
    "        eps=hyperparams[\"clustering\"][\"dbscan\"][\"eps\"],\n",
    "        min_samples=hyperparams[\"clustering\"][\"dbscan\"][\"min_samples\"],\n",
    "    )\n",
    "\n",
    "    df[\"x\"] = df.apply(lambda x: x[\"geometry\"].coords[0][0], axis=1)\n",
    "    df[\"y\"] = df.apply(lambda x: x[\"geometry\"].coords[0][1], axis=1)\n",
    "\n",
    "    df[\"x_tr\"], df[\"y_tr\"] = trans_direct.transform(df[\"x\"].values, df[\"y\"].values)\n",
    "\n",
    "    cluster_label = clusterer.fit(np.column_stack([df[\"x_tr\"], df[\"y_tr\"]])).labels_\n",
    "    df[\"cluster_label\"] = cluster_label\n",
    "    df[\"label_type\"] = \"cluster\"\n",
    "    df.loc[df.cluster_label == -1, \"label_type\"] = \"noise\"\n",
    "\n",
    "    hull_df = df[[\"geometry\", \"cluster_label\"]].dissolve(\"cluster_label\").convex_hull.to_frame().reset_index()\n",
    "\n",
    "    df = df.merge(\n",
    "        hull_df,\n",
    "        on=\"cluster_label\",\n",
    "    )\n",
    "    df.rename(columns={0: \"cluster_hull\"}, inplace=True)\n",
    "    \n",
    "    enc_circle = df.groupby(\"cluster_label\")[[\"geometry\", \"x\", \"y\"]].apply(\n",
    "        smallest_enclosing_circle\n",
    "    ).to_frame().reset_index().rename(columns={0: \"enc_circle\"})\n",
    "\n",
    "    df = df.merge(enc_circle)\n",
    "    df.loc[df.cluster_label == -1, \"cluster_hull\"] = np.nan\n",
    "    df.loc[df.cluster_label == -1, \"enc_circle\"] = np.nan\n",
    "    df[\"n_samples_clust\"] = df.groupby(\"cluster_label\")[\"osmid\"].transform(\"count\")\n",
    "    \n",
    "    return df.drop(columns=[\"x\", \"y\", \"x_tr\", \"y_tr\"])\n",
    "\n",
    "for item in [\"semaforo\"]:\n",
    "    df_dict[item + \"_cluster\"] = cluster_items(df_dict[item], item)\n",
    "    clust_df = df_dict[item + \"_cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_intersect = hyperparams[\"clustering\"][\"shared_grid\"]\n",
    "\n",
    "# Spatial merge grid with cluster hulls\n",
    "merge_hull_df = clust_df\\\n",
    "        [clust_df.cluster_label != -1]\\\n",
    "        [[\"cluster_label\", col_to_intersect, \"n_samples_clust\"]]\\\n",
    "        .set_geometry(col_to_intersect, crs=4326)\n",
    "\n",
    "merged_grid_clust = (hex_df\n",
    "        .sjoin(\n",
    "            merge_hull_df,\n",
    "            how=\"left\",\n",
    "            predicate=\"intersects\",\n",
    "            lsuffix=\"grid\",\n",
    "            rsuffix=\"semaforo\",\n",
    "        )\n",
    "    )\n",
    "merged_grid_clust = merged_grid_clust.drop(\"index_semaforo\", axis=1)\n",
    "\n",
    "\n",
    "# Spatial merge single traffic lights with grids\n",
    "merge_tl_df = clust_df\\\n",
    "        [clust_df.cluster_label != -1]\\\n",
    "        [[\"osmid\", \"geometry\", \"cluster_label\"]]\n",
    "\n",
    "merged_grid_clust = (merged_grid_clust\n",
    "        .sjoin(\n",
    "            merge_tl_df,\n",
    "            how=\"left\",\n",
    "            predicate=\"contains\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "merged_grid_clust = merged_grid_clust[\n",
    "    (merged_grid_clust.cluster_label_left == merged_grid_clust.cluster_label_right)\n",
    "    |\n",
    "    (merged_grid_clust.cluster_label_left.isna())\n",
    "    ]\n",
    "\n",
    "merged_grid_clust = merged_grid_clust.drop(\"index_right\", axis=1)\n",
    "\n",
    "# Compute how many traffic lights for cluster for each grid\n",
    "# actually belong to the grid\n",
    "def compute_perc_actual_tf(df):\n",
    "    # sum of all clustered tf in the grid\n",
    "    n_tf_clusters = df.drop_duplicates(\"cluster_label_right\").n_samples_clust.sum()\n",
    "    n_tf_actual = df.osmid.nunique()\n",
    "    return round(n_tf_actual/n_tf_clusters, 3)\n",
    "    \n",
    "\n",
    "perc_actual_tf = merged_grid_clust.groupby([\"id_grid\"])[[\"osmid\", \"n_samples_clust\", \"cluster_label_right\"]]\\\n",
    "    .apply(compute_perc_actual_tf)\\\n",
    "    .to_frame().reset_index()\n",
    "\n",
    "merged_grid_clust = merged_grid_clust\\\n",
    "    .merge(perc_actual_tf, how=\"left\")\\\n",
    "    .rename(columns={0: \"perc_clust_points_actual\"})\\\n",
    "    .drop(columns=\"cluster_label_right\")\\\n",
    "    .rename(columns={\"cluster_label_left\": \"cluster_label\"})\\\n",
    "    .drop(columns=\"osmid\")\\\n",
    "    .drop_duplicates([\"id_grid\", \"cluster_label\"])\n",
    "\n",
    "\n",
    "tmp_groupby = merged_grid_clust.groupby(\"id_grid\").agg(\n",
    "    {\n",
    "        \"cluster_label\": lambda x: x.nunique(),\n",
    "        \"n_samples_clust\": [\"max\", \"mean\"]\n",
    "    }\n",
    ")\n",
    "tmp_groupby.columns = tmp_groupby.columns.droplevel()\n",
    "tmp_groupby = tmp_groupby.reset_index()\n",
    "\n",
    "merged_grid_clust = merged_grid_clust\\\n",
    "    .merge(tmp_groupby, on=\"id_grid\", how=\"left\")\n",
    "merged_grid_clust.rename(columns={\n",
    "    \"<lambda>\": \"n_clusters\",\n",
    "    \"max\": \"max_cluster_size\",\n",
    "    \"mean\": \"mean_cluster_size\"\n",
    "}, inplace=1)\n",
    "merged_grid_clust.fillna(0, inplace=True)\n",
    "\n",
    "merged_grid_clust[\"max_cluster_size\"] = merged_grid_clust[\"max_cluster_size\"].apply(lambda x: int(x))\n",
    "merged_grid_clust[\"mean_cluster_size\"] = merged_grid_clust[\"mean_cluster_size\"].apply(lambda x: round(x, 3))\n",
    "\n",
    "merged_grid_clust = merged_grid_clust\\\n",
    "    .drop_duplicates(\"id_grid\")\\\n",
    "    .drop(columns=[\"cluster_label\", \"n_samples_clust\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(city_map, item, color_point):\n",
    "    clust_df[[\"geometry\", \"cluster_label\"]][clust_df.cluster_label != -1]\\\n",
    "        .explore(\n",
    "            name=item + \" clusters\",\n",
    "            m=city_map,\n",
    "            color=color_point,\n",
    "        )\n",
    "\n",
    "    clust_df[[\"geometry\", \"cluster_label\"]][clust_df.cluster_label == -1]\\\n",
    "        .explore(\n",
    "            name=item + \" noise\",\n",
    "            m=city_map,\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "    clust_df[clust_df.cluster_label != -1][[\"cluster_hull\"]]\\\n",
    "            .set_geometry(\"cluster_hull\", crs=4326).explore(\n",
    "                name=item + \" cluster hull\",\n",
    "                m=city_map,\n",
    "                style_kwds = {\n",
    "                    \"fill\": False,\n",
    "                    \"color\": \"green\",\n",
    "                    \"weight\": 1.5\n",
    "                }\n",
    "            )\n",
    "    return city_map\n",
    "\n",
    "\n",
    "cs =iter([\"dodgerblue\"])\n",
    "city_map = plot_grid_nil_municipi(nil_and_municipi=False)\n",
    "\n",
    "for item in [\"semaforo\"]:\n",
    "    city_map = plot_clusters(city_map, item, next(cs))\n",
    "\n",
    "popup1 = folium.LatLngPopup()\n",
    "city_map.add_child(popup1)\n",
    "folium.LayerControl(collapsed=False).add_to(city_map)\n",
    "\n",
    "city_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conteggio elementi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_grid_with_items(\n",
    "        input_df,\n",
    "        item,\n",
    "        linestring=False,\n",
    "        surface=False,\n",
    "        type=False,\n",
    "        score=False,\n",
    "        centr_metrics=[]\n",
    "    ):\n",
    "    cols_to_include = [\"osmid\", \"geometry\"]\n",
    "    if surface:\n",
    "        cols_to_include = [\"osmid\", \"geometry\", \"surface_mapped\"]\n",
    "    if type:\n",
    "        cols_to_include = [\"osmid\", \"geometry\", \"highway\"]\n",
    "    if score:\n",
    "        cols_to_include = [\"osmid\", \"geometry\", *[\"avg_sub_\" + c  for c in centr_metrics]]\n",
    "    item_df = df_dict[item][cols_to_include]\n",
    "    item_df[\"osmid\"] == item_df[\"osmid\"].astype(str)\n",
    "    item_df = item_df.rename(\n",
    "        columns={\n",
    "            \"geometry\": \"{}_geometry\".format(item),\n",
    "            \"osmid\": \"{}_osmid\".format(item),\n",
    "            }\n",
    "        )\n",
    "    item_df.set_geometry(\"{}_geometry\".format(item), crs=4326, inplace=1)\n",
    "    if linestring:\n",
    "        item_df[\"geometry_length\"] = item_df[\"{}_geometry\".format(item)]\n",
    "    else:\n",
    "        input_df = input_df[[\"id_grid\", \"geometry\"]]\n",
    "\n",
    "    merged = (input_df\n",
    "        .sjoin(\n",
    "            item_df,\n",
    "            how=\"left\",\n",
    "            predicate=\"intersects\",\n",
    "            rsuffix = \"{}\".format(item),\n",
    "        )\n",
    "        .drop(\n",
    "            columns=\"index_{}\".format(item)\n",
    "        )\n",
    "    )\n",
    "    if linestring:\n",
    "        merged.set_geometry(\"geometry_length\", crs=4326, inplace=1)\n",
    "    return merged\n",
    "\n",
    "\n",
    "def count_item_points_grid(input_df, item):\n",
    "    merged = merge_grid_with_items(input_df, item)\n",
    "    merged = merged\\\n",
    "        .groupby(\"id_grid\")[\"{}_osmid\".format(item)]\\\n",
    "        .count()\\\n",
    "        .to_frame()\\\n",
    "        .reset_index()\\\n",
    "        .rename(columns={\"{}_osmid\".format(item): \"n_{}\".format(item)})\n",
    "    merged = input_df\\\n",
    "        .merge(merged, how=\"left\")\n",
    "    # merged.set_geometry(\"geometry\", inplace=1)\n",
    "    return merged\n",
    "\n",
    "\n",
    "feature_df = merged_grid_clust\n",
    "feature_df = gpd.GeoDataFrame(feature_df, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "list_item_count = [\n",
    "    \"precedenza\",\n",
    "    \"semaforo\",\n",
    "    \"stop\"\n",
    "]\n",
    "for item in list_item_count:\n",
    "    print(item)\n",
    "    feature_df = count_item_points_grid(feature_df, item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calcolo lunghezze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_length(input_df, item):\n",
    "    merged = merge_grid_with_items(input_df, item, linestring=True)\n",
    "    merged = merged.dissolve(\"id_grid\", as_index=False)\n",
    "    merged[\"length_{}\".format(item)] = round(merged[\"geometry_length\"].to_crs(32632).length, 3)\n",
    "    merged.drop(columns=[\n",
    "        \"{}_osmid\".format(item),\n",
    "        \"geometry_length\",\n",
    "    ], inplace=True)\n",
    "\n",
    "    merged.set_geometry(\"geometry\", crs=4326, inplace=True)\n",
    "\n",
    "    return merged\n",
    "\n",
    "list_item_length = [\n",
    "    \"rotatoria\",\n",
    "    \"rotaie_tram\"\n",
    "]\n",
    "\n",
    "df = df_dict[\"rotatoria\"]\n",
    "df = df[~(df[\"highway\"].str.contains(\"motorway\"))]\n",
    "df_dict[\"rotatoria\"] = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=4236)\n",
    "\n",
    "for item in list_item_length:\n",
    "    print(item)\n",
    "    feature_df = compute_length(feature_df, item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Percentuale asfalto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perc_asphalt(input_df, item):\n",
    "    merged = merge_grid_with_items(input_df, item, linestring=True, surface=True)\n",
    "    \n",
    "    asphalt_length = merged[merged.surface_mapped == \"asphalt\"].dissolve(\"id_grid\", as_index=False)\n",
    "    asphalt_length[\"asph_length_{}\".format(item)] = round(asphalt_length[\"geometry_length\"].to_crs(32632).length, 3)\n",
    "    asphalt_length = asphalt_length[[\"id_grid\", \"asph_length_{}\".format(item)]]\n",
    "\n",
    "    total_length = merged.dissolve(\"id_grid\", as_index=False)\n",
    "    total_length[\"tot_length_{}\".format(item)] = round(total_length[\"geometry_length\"].to_crs(32632).length, 3)\n",
    "    total_length = total_length[[\"id_grid\", \"tot_length_{}\".format(item)]]\n",
    "\n",
    "    tmp = total_length\\\n",
    "        .merge(asphalt_length, how=\"left\").fillna(0)\n",
    "    tmp[\"perc_asphalt\"] = round(tmp[\"asph_length_manto_stradale\"]/tmp[\"tot_length_manto_stradale\"], 3)\n",
    "    tmp.drop(\n",
    "        columns=\n",
    "        [\n",
    "            \"asph_length_manto_stradale\",\n",
    "            \"tot_length_manto_stradale\",\n",
    "        ],\n",
    "        inplace=True\n",
    "    )\n",
    "    merged = merged.drop(\n",
    "        columns=\n",
    "        [\n",
    "            \"surface_mapped\",\n",
    "            \"{}_osmid\".format(item),\n",
    "            \"geometry_length\"\n",
    "        ]\n",
    "        ).drop_duplicates(\"id_grid\")\n",
    "\n",
    "    merged = merged\\\n",
    "        .merge(tmp, how=\"left\")\n",
    "    merged = merged.set_geometry(\"geometry\", crs=4326)\n",
    "    return merged\n",
    "\n",
    "df = df_dict[\"manto_stradale\"]\n",
    "df = df[~(df[\"highway\"].str.contains(\"motorway\"))]\n",
    "df_dict[\"manto_stradale\"] = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=4236)\n",
    "\n",
    "feature_df = compute_perc_asphalt(feature_df, \"manto_stradale\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Totale lunghezza strade per tipo di strada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dict[\"roads_graph_data\"]\n",
    "df = df[~(df[\"highway\"].str.contains(\"motorway\"))]\n",
    "df[\"osmid\"] = df[\"u\"].astype(str) + df[\"v\"].astype(str)\n",
    "df_dict[\"roads_graph_data\"] = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=4236)\n",
    "\n",
    "feature_df = compute_length(\n",
    "    gpd.GeoDataFrame(feature_df, geometry=\"geometry\", crs=4326),\n",
    "    \"roads_graph_data\"\n",
    ")\n",
    "\n",
    "def compute_type_road_length(input_df, item):\n",
    "    merged = merge_grid_with_items(input_df, item, linestring=True, type=True)\n",
    "\n",
    "    for t in [\n",
    "        \"residential\",\n",
    "        \"primary\",\n",
    "        \"secondary\",\n",
    "        \"tertiary\",\n",
    "        \"living_street\",\n",
    "        \"unclassified\",\n",
    "    ]:\n",
    "    \n",
    "        type_length = merged[merged.highway.str.contains(t, na=False)].dissolve([\"id_grid\", \"highway\"], as_index=False)\n",
    "        type_length[\"{}_road_length\".format(t)] = round(type_length[\"geometry_length\"].to_crs(32632).length, 3)\n",
    "        type_length = type_length[[\"id_grid\", \"{}_road_length\".format(t)]]\n",
    "\n",
    "        merged = merged\\\n",
    "            .merge(type_length, how=\"left\")\n",
    "        \n",
    "    merged = merged.drop(\n",
    "        columns=\n",
    "        [\n",
    "            \"highway\",\n",
    "            \"{}_osmid\".format(item),\n",
    "            \"geometry_length\"\n",
    "        ]\n",
    "        ).drop_duplicates(\"id_grid\")\n",
    "    \n",
    "    merged.set_geometry(\"geometry\", crs=4326, inplace=True)\n",
    "    return merged\n",
    "\n",
    "feature_df = compute_type_road_length(feature_df, \"roads_graph_data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metriche di centralità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_avg_centrality_grid(input_df, item, centr_metrics):\n",
    "    merged = merge_grid_with_items(input_df, item, centr_metrics=centr_metrics, score=True)\n",
    "    cols = [\"avg_sub_\" + c for c in centr_metrics]\n",
    "    merged = merged\\\n",
    "        .groupby(\"id_grid\")[cols]\\\n",
    "        .mean()\\\n",
    "        .reset_index()\n",
    "    merged = input_df\\\n",
    "        .merge(merged, how=\"left\")\n",
    "    merged = merged.rename(columns={\n",
    "        \"avg_sub_\" + c: \"avg_grid_\" + c for c in centr_metrics\n",
    "    })\n",
    "    for c in centr_metrics: merged[\"avg_grid_\" + c] = round(merged[\"avg_grid_\" + c], 3)\n",
    "    merged.set_geometry(\"geometry\", crs=4326, inplace=True)\n",
    "    return merged\n",
    "\n",
    "centr_metrics = [\"betweenness\", \"closeness\", \"adjacent_roads\"]\n",
    "\n",
    "feature_df = count_avg_centrality_grid(feature_df, \"roads_graph_data\", centr_metrics)\n",
    "\n",
    "def length_percentile_centrality_grid(input_df, item, centr_metrics):\n",
    "    merged = merge_grid_with_items(input_df, item, linestring=True, centr_metrics=centr_metrics, score=True)\n",
    "    for cen in centr_metrics:\n",
    "    \n",
    "        cen_length = merged[merged[\"avg_sub_\" + cen] >= perc_dict[\"avg_sub_\" + cen]].dissolve(\"id_grid\", as_index=False)\n",
    "        cen_length[\"{}_perc_{}_length\".format(int(percentile*100), cen)] = round(cen_length[\"geometry_length\"].to_crs(32632).length, 3)\n",
    "        cen_length = cen_length[[\"id_grid\", \"{}_perc_{}_length\".format(int(percentile*100), cen)]]\n",
    "\n",
    "        merged = merged.drop(columns=\"avg_sub_\" + cen)\\\n",
    "            .merge(cen_length, how=\"left\")\n",
    "        \n",
    "    merged = merged.drop(\n",
    "        columns=\n",
    "        [\n",
    "            \"{}_osmid\".format(item),\n",
    "            \"geometry_length\",\n",
    "        ]\n",
    "        ).drop_duplicates(\"id_grid\")\n",
    "    \n",
    "    merged.set_geometry(\"geometry\", crs=4326, inplace=True)\n",
    "    return merged\n",
    "\n",
    "feature_df = length_percentile_centrality_grid(feature_df, \"roads_graph_data\", centr_metrics)\n",
    "feature_df = feature_df.fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlazione tra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "def corr_matrix(df):\n",
    "    \n",
    "\n",
    "    df = df.corr()\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    # define the mask to set the values in the upper triangle to True\n",
    "    mask = np.triu(np.ones_like(df, dtype=bool))\n",
    "    heatmap = sns.heatmap(\n",
    "        df,\n",
    "        mask=mask,\n",
    "        vmin=df.min().min(),\n",
    "        vmax=df.max().max(),\n",
    "        annot=True,\n",
    "        cmap=\"coolwarm\",\n",
    "        annot_kws={\"size\": 9},\n",
    "        linewidths=.2,\n",
    "        linecolor=\"white\"\n",
    "    )\n",
    "    heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=45, horizontalalignment=\"right\")\n",
    "    # heatmap.xaxis.tick_bottom()\n",
    "\n",
    "    heatmap.set_title(\"Feature correlation\", fontdict={\"fontsize\":18}, pad=16)\n",
    "\n",
    "\n",
    "corr_matrix(feature_df.iloc[:, 6:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "display",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d409ddddaeed9b6e59d5d328e0b59ef0feee71f4479230efcc2fd3db8066d4d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
